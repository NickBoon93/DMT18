{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.springboard.com/blog/data-mining-python-tutorial/\n",
    "\n",
    "http://www.developintelligence.com/blog/2017/08/data-cleaning-pandas-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ODI-2018.csv',skiprows=[1])\n",
    "clean = df.copy()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for value types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/20250771/remap-values-in-pandas-column-with-a-dict\n",
    "data = df[df.columns[1]].str.lower()\n",
    "data = data.str.strip()\n",
    "data = data.str.replace('&','and') \n",
    "clean[df.columns[1]] = data.replace(\n",
    "    {'21-05-1995':np.NaN,\n",
    "    'a. i.':'Artificial Intelligence',\n",
    "    'ai':'Artificial Intelligence',\n",
    "    'ai (cognitive sciences)':'Artificial Intelligence',\n",
    "    'ai (vu version)':'Artificial Intelligence',\n",
    "    'ai vu':'Artificial Intelligence',\n",
    "    'ai premaster':'Artificial Intelligence',\n",
    "    'artificial intelligence (socially aware computing)':'Artificial Intelligence',\n",
    "    'artificial intelligence':'Artificial Intelligence',\n",
    "    'ba':'Business Analytics',\n",
    "    'b science, business and innovation':'Science, Business & Innovation',\n",
    "    'big data engineering':'Computer Science',\n",
    "    'bioinformatcis':'Bioinformatics & Systems Biology',\n",
    "    'bioinformatics and system biology':'Bioinformatics & Systems Biology',\n",
    "    'bioinformatics':'Bioinformatics & Systems Biology',\n",
    "    'bioinformatics and systems biology':'Bioinformatics & Systems Biology',\n",
    "    'bioinformatics and sysbio':'Bioinformatics & Systems Biology',\n",
    "    'bioinformatics master':'Bioinformatics & Systems Biology',\n",
    "    'business analytics msc':'Business Analytics',\n",
    "    'business analytics/ operations research':'Business Analytics',\n",
    "    'business analytics':'Business Analytics',\n",
    "    'cls':'Computational Science',\n",
    "    'cs':'Computer Science',\n",
    "    'csl':'Computational Science',\n",
    "    'comoputational science':'Computational Science',\n",
    "    'computational science (jd)':'Computational Science',\n",
    "    'computational science':'Computational Science',\n",
    "    'computer science':'Computer Science',\n",
    "    'computer science: big data engineering':'Computer Science',\n",
    "    'data mining techniques':np.NaN,\n",
    "    'drug discovery and safety':'Drug Discovery and Safety',\n",
    "    'duisenberg honors program quantitative risk managament':'Quantitative Risk Management',\n",
    "    'duisenberg quantitative risk management':'Quantitative Risk Management',\n",
    "    'econometrics':'Econometrics',\n",
    "    'econometrics and operations research':'Econometrics and Operations Research',\n",
    "    'economics':'Economics',\n",
    "    'eor':'Econometrics and Operations Research',\n",
    "    'exchange':'Exchange student',\n",
    "    'finance':'Finance',\n",
    "    'finance dhp qrm':'Quantitative Risk Management',\n",
    "    'm financial economtrics':'Econometrics',\n",
    "    'ma bioinformatics':'Bioinformatics & Systems Biology',\n",
    "    'master bionformatics and systems biology':'Bioinformatics & Systems Biology',\n",
    "    'master business analytics':'Business Analytics',\n",
    "    'master computer science: big data engineering':'Computer Science',\n",
    "    'master econometrics and operations research':'Econometrics and Operations Research',\n",
    "    'master human movement science':'Human Movement Sciences',\n",
    "    'masters computer science(big data engineering)':'Computer Science',\n",
    "    'mathematics':'Mathematics',\n",
    "    'mathematics exchange':'Exchange student',\n",
    "    'mpa':'Management, Policy-Analysis & Entrepreneurship in Health and Life Sciences',\n",
    "    'ms':np.NaN,\n",
    "    'msc ai and msc cls':'Artificial Intelligence',\n",
    "    'msc artificial intelligence':'Artificial Intelligence',\n",
    "    'msc bioinformatics':'Bioinformatics & Systems Biology',\n",
    "    'msc bioinformatics and systems biology':'Bioinformatics & Systems Biology',\n",
    "    'msc computational science':'Computational Science',\n",
    "    'msc computational science (joint degree)':'Computational Science',\n",
    "    'msc computer science':'Computer Science',\n",
    "    'msc econometrics':'Econometrics',\n",
    "    'msc. bioinformatics and systems biology':'Bioinformatics & Systems Biology',\n",
    "    'or':'Econometrics and Operations Research',\n",
    "    'phd':'PhD',\n",
    "    'phd student':'PhD',\n",
    "    'phd student at fgb':'PhD',\n",
    "    'physics':'Physics',\n",
    "    'qrm':'Quantitative Risk Management',\n",
    "    'quantitative risk management':'Quantitative Risk Management',\n",
    "    'system biology and bioinformatics':'Bioinformatics & Systems Biology'\n",
    "    })\n",
    "Counter(df[df.columns[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns[2])\n",
    "Counter(clean[df.columns[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns[3])\n",
    "clean[df.columns[3]] = df[df.columns[3]].replace({\n",
    "    '0':'no',\n",
    "    '1':'yes'\n",
    "})\n",
    "Counter(clean[df.columns[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns[4])\n",
    "clean[df.columns[4]] = df[df.columns[4]].replace({\n",
    "    'sigma':'no',\n",
    "    'mu':'yes'\n",
    "})\n",
    "Counter(clean[df.columns[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns[5])\n",
    "clean[df.columns[5]] = df[df.columns[5]].replace({\n",
    "    'nee':'no',\n",
    "    'ja':'yes'\n",
    "})\n",
    "Counter(clean[df.columns[5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns[6])\n",
    "Counter(df[df.columns[6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns[7])\n",
    "Counter(df[df.columns[7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def clean_date(data):\n",
    "    #try to obtain DD-MM dates\n",
    "    \n",
    "    #dict to replace month names to month number\n",
    "    monthtoyear = {'january':1,'february':2,'march':3,'april':4,'may':5,\\\n",
    "                   'june':6,'july':7,'august':8,'september':9,'october':10,\\\n",
    "                   'november':11,'december':12,'aug':8,'februari':2}\n",
    "    #replace DD/MM, DD.MM or DDth MMM notations\n",
    "    data = data.str.replace(\"/\",\"-\")\n",
    "    data = data.str.replace(\".\",\"-\")\n",
    "    data = data.str.replace(\" \",\"-\")\n",
    "    data = data.str.replace(\"th\",\"\")\n",
    "    \n",
    "    #init empty list to store cleaned dates\n",
    "    cleaned = []\n",
    "    \n",
    "    for i in data.values:\n",
    "        #try to split string into DD, MM, YYYY\n",
    "        try:\n",
    "            date = i.split(\"-\")\n",
    "        except:\n",
    "            date = np.NaN\n",
    "        \n",
    "        #convert first element, which may be DD, MMM or YYYY\n",
    "        #e.g. 28-10-1994 or March 24th etc.\n",
    "        try:\n",
    "            first = int(date[0])\n",
    "        except:\n",
    "            try:\n",
    "                first = monthtoyear[date[0].lower()]\n",
    "            except:\n",
    "                first = np.NaN\n",
    "        \n",
    "        #same for second element\n",
    "        try:\n",
    "            second = int(date[1])\n",
    "        except:\n",
    "            try:\n",
    "                second = monthtoyear[date[1].lower()]\n",
    "            except:\n",
    "                second = np.NaN\n",
    "        \n",
    "        #third is always YYYY or DD, never MMM\n",
    "        try:\n",
    "            third = int(date[2])\n",
    "        except:\n",
    "            third = np.NaN\n",
    "        \n",
    "        if second > 12 and first <= 12:\n",
    "            #assume MM-DD\n",
    "            cleaned.append(\"%02d-%02d\"%(second,first))\n",
    "        elif first <= 31 and second <= 12:\n",
    "            #assume DD-MM\n",
    "            cleaned.append(\"%02d-%02d\"%(first,second))\n",
    "        elif first > 1900 and second <= 12 and third <= 31:\n",
    "            #assume YYYY-MM-DD\n",
    "            cleaned.append(\"%02d-%02d\"%(third,second))\n",
    "        elif first > 1900 and second <= 31 and third <= 12:\n",
    "            #assume YYYY-DD-MM\n",
    "            cleaned.append(\"%02d-%02d\"%(second,third))\n",
    "        else:\n",
    "            #cannot get data, return NaN\n",
    "            cleaned.append(np.NaN)\n",
    "            \n",
    "    cleaned = pd.Series(cleaned)\n",
    "    return cleaned\n",
    "        \n",
    "print(df.columns[8])\n",
    "clean[df.columns[8]] = clean_date(df[df.columns[8]])    \n",
    "Counter(clean[df.columns[8]])\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "#drop NaN, split on '-' and obtain months only\n",
    "data = np.array(clean[df.columns[8]].dropna().str.split('-').values.tolist())[:,1]\n",
    "ax.hist(data.astype(int),np.arange(0.5,13.5,1),ec='black')\n",
    "ax.set_title(\"Distribution of birthdate month\")\n",
    "ax.set_xlabel(\"Month\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "\n",
    "fig.savefig(\"dist_month.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns[9])\n",
    "data = df[df.columns[9]]\n",
    "data = data.apply(pd.to_numeric,errors='coerce') #non-numeric -> NaN\n",
    "data = data.mask(data.lt(0) | data.gt(8))        #cannot have more than 8 neighbours!\n",
    "data = data.round()                              #can only have integer neighbours (error due to NaNs)\n",
    "clean[df.columns[9]] = data\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.hist(data.dropna().values, np.arange(-0.5,9.5,1), ec='black');\n",
    "ax.set_title(\"Distribution of number of neighbours\")\n",
    "ax.set_xlabel(\"Neighbours\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "\n",
    "Counter(clean[df.columns[9]].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns[10])\n",
    "Counter(df[df.columns[10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(df.columns[11])\n",
    "data = df[df.columns[11]]\n",
    "data = data.apply(pd.to_numeric,errors='coerce') #convert values to numerical\n",
    "data = data.mask(data.lt(0) | data.gt(100))      #can only be between 0 and 100\n",
    "data = data.round(2)\n",
    "clean[df.columns[11]] = data\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(8,6))\n",
    "ax.hist(data.dropna().values,np.arange(-2.5,107.5,5), ec='black')\n",
    "ax.set_title(\"Distribution of money gained\")\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(8,6))\n",
    "ax.hist(data.dropna().values, np.arange(-0.125,5.375,0.25), ec='black')\n",
    "ax.set_title(\"Distribution of money gained\")\n",
    "\n",
    "Counter(data.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning random number column and plotting histogram of numbers 0-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/a/34844867\n",
    "#https://stackoverflow.com/a/41618665\n",
    "#https://stackoverflow.com/a/40442778\n",
    "data = df[df.columns[12]]\n",
    "data = data.str.replace('ACHT','8')\n",
    "data = data.apply(pd.to_numeric,errors='coerce') #non-numeric -> NaN\n",
    "data = data.mask(data.lt(0) | data.gt(10))       #can only be 0 - 10\n",
    "cleaned = []\n",
    "for i in data.values:\n",
    "    if np.isnan(i):\n",
    "        cleaned.append(np.NaN)\n",
    "    else:\n",
    "        cleaned.append(i)\n",
    "data = pd.Series(cleaned)\n",
    "clean[df.columns[12]] = data\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.hist(data.dropna().values, np.arange(-0.5,11.5,1), ec='black');\n",
    "ax.set_title(\"Random number distribution\")\n",
    "ax.set_xlabel(\"Value\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "fig.savefig(\"dist_random.pdf\")\n",
    "\n",
    "Counter(data.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(df.columns[13])\n",
    "data = df[df.columns[13]]\n",
    "#https://stackoverflow.com/a/15321222\n",
    "data = data.str.decode('unicode_escape').str.encode('ascii','ignore').str.decode('ascii')\n",
    "data = data.str.lower()\n",
    "data = data.str.replace(' ','')\n",
    "data = data.str.replace('a.m.','')\n",
    "data = data.str.replace('am','')\n",
    "data = data.str.replace('pm','')\n",
    "data = data.str.replace(' ','')\n",
    "data = data.str.replace('.',':')\n",
    "data = data.str.replace('300','3:00')\n",
    "data = data.str.replace('2330','23:30')\n",
    "data = data.str.replace('2359','23:59')\n",
    "cleaned = []\n",
    "for i in data.values:\n",
    "    \n",
    "    #split hour:minute\n",
    "    time = i.split(':')\n",
    "    \n",
    "    #answered in hours or without :\n",
    "    if len(time) == 1:\n",
    "        try:\n",
    "            hour = int(time[0])\n",
    "            minute = 0\n",
    "        except:\n",
    "            hour = np.NaN\n",
    "            minute = np.NaN\n",
    "    \n",
    "    #answered in hour:minute\n",
    "    else:\n",
    "        hour = int(time[0])\n",
    "        minute = int(time[1])\n",
    "    \n",
    "    #assume 12-hour notation if time to bed between 8-12\n",
    "    if hour >= 8 and hour <= 12:\n",
    "        hour += 12\n",
    "    if hour == 24:\n",
    "        hour -= 24\n",
    "    \n",
    "    #sanity check\n",
    "    if hour > 24 or minute > 59:\n",
    "        hour = np.NaN\n",
    "        minute = np.NaN\n",
    "    \n",
    "    if np.isnan(hour):\n",
    "        cleaned.append(np.NaN)\n",
    "    else:\n",
    "        cleaned.append(\"%02d:%02d\"%(hour,minute))\n",
    "        \n",
    "clean[df.columns[13]] = pd.Series(cleaned)\n",
    "\n",
    "#split hh:mm on :\n",
    "data = np.array(clean[df.columns[13]].dropna().str.split(':').values.tolist())\n",
    "#get nearest hour\n",
    "data = np.round(data[:,0].astype(int)+data[:,1].astype(int)/60)%24\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(8,6))\n",
    "ax.hist(data,np.arange(-0.5,24.5,1),ec='black')\n",
    "ax.set_title(\"Time to bed yesterday (hour)\")\n",
    "ax.set_xlabel(\"Hour\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "fig.savefig(\"dist_timetobed.pdf\")\n",
    "\n",
    "x = Counter(pd.Series(cleaned).dropna())\n",
    "sorted(x.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clean.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Basic regression/classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
