{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import datetime\n",
    "from operator import itemgetter\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete example using RandomForestClassifier\n",
    "\n",
    "https://github.com/benhamner/ExpediaPersonalizedSortCompetition/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test set\n",
    "test = pd.read_csv('../../training_set_VU_DM_2014.csv').fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n"
     ]
    }
   ],
   "source": [
    "# obtain feature names and remove useless column date_time\n",
    "feature_names = list(test.columns)\n",
    "feature_names.remove(\"date_time\")\n",
    "\n",
    "# obtain feature values\n",
    "features = test[feature_names].values\n",
    "\n",
    "ids = test[\"srch_id\"].unique()\n",
    "np.random.shuffle(ids)\n",
    "ids = ids[0:1000]\n",
    "\n",
    "test = test.loc[test[\"srch_id\"].isin(ids)]\n",
    "\n",
    "test[\"rel\"] = test[\"booking_bool\"] + test[\"click_bool\"]\n",
    "test[\"rel\"] = test[\"rel\"].map({0:0,1:1,2:5})\n",
    "\n",
    "# predict using trained model\n",
    "print(\"Making predictions\")\n",
    "predictions = np.random.random(len(test))\n",
    "predictions = list(-1.0*predictions)\n",
    "recommendations = zip(test[\"srch_id\"], test[\"prop_id\"], test[\"booking_bool\"], test[\"click_bool\"], predictions,test[\"rel\"])\n",
    "    \n",
    "rows = [(srch_id, prop_id,booking_bool,click_bool,rel)\n",
    "    for srch_id, prop_id,booking_bool,click_bool, rank_float, rel\n",
    "    in sorted(recommendations, key=itemgetter(0,4))]\n",
    "\n",
    "with open(\"predict.csv\", \"w\") as outfile:\n",
    "    writer = csv.writer(outfile, lineterminator=\"\\n\")\n",
    "    writer.writerow((\"SearchId\", \"PropertyId\", \"BookingBool\",\"ClickBool\",\"rel\"))\n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/wendykan/ndcg-example\n",
    "\"\"\" Reference from https://gist.github.com/bwhite/3726239\n",
    "\"\"\"\n",
    "def dcg_at_k(r, k):\n",
    "    \"\"\"Score is discounted cumulative gain (dcg)\n",
    "    Relevance is positive real values.  Can use binary\n",
    "    as the previous methods.\n",
    "    Example from\n",
    "    http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
    "    Args:\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "        k: Number of results to consider\n",
    "        weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "    Returns:\n",
    "        Discounted cumulative gain\n",
    "    \"\"\"\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        return np.sum((2 ** r -1)/ np.log2(np.arange(2, r.size + 2)))\n",
    "    return 0.\n",
    "\n",
    "\n",
    "def ndcg_at_k(r, k):\n",
    "    \"\"\"Score is normalized discounted cumulative gain (ndcg)\n",
    "    Relevance is positive real values.  Can use binary\n",
    "    as the previous methods.\n",
    "    Example from\n",
    "    http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
    "    Args:\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "        k: Number of results to consider\n",
    "        weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "    Returns:\n",
    "        Normalized discounted cumulative gain\n",
    "    \"\"\"\n",
    "    \n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True), k)\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k) / dcg_max\n",
    "\n",
    "score = []\n",
    "result = pd.read_csv('predict.csv')\n",
    "score_n = 0\n",
    "for srch_id in result[\"SearchId\"].unique():\n",
    "    #use NDCG@38 as per Kaggle site\n",
    "    score_n += ndcg_at_k(result.loc[result[\"SearchId\"]==srch_id,\"rel\"].values,38)\n",
    "score.append(score_n / len(result[\"SearchId\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35341455368709124]\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
