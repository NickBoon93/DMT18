{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import datetime\n",
    "from operator import itemgetter\n",
    "import csv\n",
    "\n",
    "pd.set_option('display.max_columns',50)\n",
    "pd.set_option('display.max_rows',50)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sites to look at\n",
    "\n",
    "https://www.dataquest.io/blog/kaggle-tutorial/\n",
    "\n",
    "Need one-hot encoding for our categorical data if using scikit randomforest\n",
    "\n",
    "https://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold cross-validation of Random Forest Classifier with added features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../training_set_VU_DM_2014.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert time-fields to usable features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert date_time to datetime\n",
    "df[\"date_time\"] = pd.to_datetime(df[\"date_time\"])\n",
    "\n",
    "#add column for the starting date of the booking\n",
    "df[\"book_start\"] = df[\"date_time\"] + pd.to_timedelta(df['srch_booking_window'], unit='D')\n",
    "df[\"book_end\"] = df[\"book_start\"] + pd.to_timedelta(df['srch_length_of_stay'], unit='D')\n",
    "\n",
    "#extract usable features\n",
    "df[\"srch_weekday\"] = df[\"date_time\"].dt.weekday\n",
    "df[\"srch_month\"] = df[\"date_time\"].dt.month\n",
    "df[\"srch_quarter\"] = df[\"date_time\"].dt.quarter\n",
    "df[\"srch_year\"] = df[\"date_time\"].dt.year\n",
    "df[\"book_start_weekday\"] = df[\"book_start\"].dt.weekday\n",
    "df[\"book_start_month\"] = df[\"book_start\"].dt.month\n",
    "df[\"book_start_quarter\"] = df[\"book_start\"].dt.quarter\n",
    "df[\"book_start_year\"] = df[\"book_start\"].dt.year\n",
    "df[\"book_end_weekday\"] = df[\"book_end\"].dt.weekday\n",
    "df[\"book_end_month\"] = df[\"book_end\"].dt.month\n",
    "df[\"book_end_quarter\"] = df[\"book_end\"].dt.quarter\n",
    "df[\"book_end_year\"] = df[\"book_end\"].dt.year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Some feature engineering with competitor columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take minimum of comp#_rate columns. If Expedia is cheaper than all competitors (all are 1), this will be 1.\n",
    "#If one competitor is cheaper (-1), this column will equal -1 (and have less chance of being booked at Expedia!)\n",
    "df[\"comp\"] = df[[\"comp%d_rate\"%i for i in range(1,9)]].min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiply comp_rate and comp_rate_percent_diff and drop the old columns\n",
    "for i in range(1,9):\n",
    "    df[\"comp%d\"%i] = df[\"comp%d_rate\"%i] * df[\"comp%d_rate_percent_diff\"%i]\n",
    "    df.drop([\"comp%d_rate\"%i, \"comp%d_rate_percent_diff\"%i],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/a/30949063\n",
    "\n",
    "df['avg_prop_starrating'] = df.groupby('srch_id')['prop_starrating'].transform('mean')\n",
    "df['avg_prop_location_score1'] = df.groupby('srch_id')['prop_location_score1'].transform('mean')\n",
    "df['avg_prop_location_score2'] = df.groupby('srch_id')['prop_location_score2'].transform('mean')\n",
    "df['avg_price_usd'] = df.groupby('srch_id')['price_usd'].transform('mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create difference columns, comparing the average with the value of each row\n",
    "df['avg_prop_starrating_diff'] = df['prop_starrating'] - df['avg_prop_starrating']\n",
    "df['avg_prop_location_score1_diff'] = df['prop_location_score1'] - df['avg_prop_location_score1']\n",
    "df['avg_prop_location_score2_diff'] = df['prop_location_score2'] - df['avg_prop_location_score2']\n",
    "df['avg_price_usd_diff'] = df['avg_price_usd'] - df['price_usd'] #cheaper is better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split training set into training and test set for evaluating performance\n",
    "\n",
    "We don't have book_bool in the test set provided, so we can do this to estimate performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TOTAL SEARCHES IN DATASET: %d\"%len(df[\"srch_id\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#perform 10-fold cross-validation over a subset of the data\n",
    "splits = 10\n",
    "ids = df[\"srch_id\"].unique()\n",
    "np.random.shuffle(ids)\n",
    "ids = ids[0:int(len(ids)/splits)*splits] #drop some srch_ids to keep test set sizes equal\n",
    "split_ids = np.split(ids,splits)\n",
    "\n",
    "result = []\n",
    "\n",
    "for n,i in enumerate(split_ids):\n",
    "    \n",
    "    test_set = df.loc[df[\"srch_id\"].isin(i)]\n",
    "    training_set = df.loc[~(df[\"srch_id\"].isin(i)) & (df[\"srch_id\"].isin(ids))]\n",
    "#     print(len(test_set[\"srch_id\"].unique()))\n",
    "#     print(len(training_set[\"srch_id\"].unique()))\n",
    "    \n",
    "    #do something with NaN? For now, just set to zero\n",
    "    \n",
    "    #this code is based on the benchmark code given at\n",
    "    #https://github.com/benhamner/ExpediaPersonalizedSortCompetition/\n",
    "    \n",
    "    test_set.fillna(0,inplace=True)\n",
    "    training_set.fillna(0,inplace=True)\n",
    "    \n",
    "    #train model\n",
    "    feature_names = list(training_set.columns)\n",
    "    feature_names.remove(\"date_time\")\n",
    "    feature_names.remove(\"book_start\")\n",
    "    feature_names.remove(\"book_end\")\n",
    "    feature_names.remove(\"position\")\n",
    "    feature_names.remove(\"click_bool\")\n",
    "    feature_names.remove(\"gross_bookings_usd\")\n",
    "    feature_names.remove(\"random_bool\")\n",
    "    feature_names.remove(\"booking_bool\")\n",
    "    features = training_set[feature_names].values\n",
    "    target = training_set[\"booking_bool\"].values\n",
    "    classifier = RandomForestClassifier(n_estimators=50, \n",
    "                                        verbose=1,\n",
    "                                        n_jobs=4,\n",
    "                                        min_samples_split=10,\n",
    "                                        random_state=1)\n",
    "    classifier.fit(features, target)\n",
    "    \n",
    "    #test model\n",
    "    feature_names = list(test_set.columns)\n",
    "    feature_names.remove(\"date_time\")\n",
    "    feature_names.remove(\"book_start\")\n",
    "    feature_names.remove(\"book_end\")\n",
    "    feature_names.remove(\"position\")\n",
    "    feature_names.remove(\"click_bool\")\n",
    "    feature_names.remove(\"gross_bookings_usd\")\n",
    "    feature_names.remove(\"random_bool\")\n",
    "    feature_names.remove(\"booking_bool\")\n",
    "    features = test_set[feature_names].values\n",
    "    \n",
    "    predictions = classifier.predict_proba(features)[:,1]\n",
    "    predictions = list(-1.0*predictions)\n",
    "    recommendations = zip(test_set[\"srch_id\"], test_set[\"prop_id\"], test_set[\"booking_bool\"], test_set[\"click_bool\"], predictions)\n",
    "    \n",
    "    rows = [(srch_id, prop_id,booking_bool,click_bool)\n",
    "        for srch_id, prop_id,booking_bool,click_bool, rank_float\n",
    "        in sorted(recommendations, key=itemgetter(0,4))]\n",
    "    \n",
    "    with open(\"predict%d.csv\"%n, \"w\") as outfile:\n",
    "        writer = csv.writer(outfile, lineterminator=\"\\n\")\n",
    "        writer.writerow((\"SearchId\", \"PropertyId\", \"BookingBool\",\"ClickBool\"))\n",
    "        writer.writerows(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevance(row):\n",
    "    if row[\"BookingBool\"]:\n",
    "        return 5\n",
    "    elif row[\"ClickBool\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#https://www.kaggle.com/wendykan/ndcg-example\n",
    "\"\"\" Reference from https://gist.github.com/bwhite/3726239\n",
    "\"\"\"\n",
    "def dcg_at_k(r, k, method=0):\n",
    "    \"\"\"Score is discounted cumulative gain (dcg)\n",
    "    Relevance is positive real values.  Can use binary\n",
    "    as the previous methods.\n",
    "    Example from\n",
    "    http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
    "    >>> r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "    >>> dcg_at_k(r, 1)\n",
    "    3.0\n",
    "    >>> dcg_at_k(r, 1, method=1)\n",
    "    3.0\n",
    "    >>> dcg_at_k(r, 2)\n",
    "    5.0\n",
    "    >>> dcg_at_k(r, 2, method=1)\n",
    "    4.2618595071429155\n",
    "    >>> dcg_at_k(r, 10)\n",
    "    9.6051177391888114\n",
    "    >>> dcg_at_k(r, 11)\n",
    "    9.6051177391888114\n",
    "    Args:\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "        k: Number of results to consider\n",
    "        method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "                If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "    Returns:\n",
    "        Discounted cumulative gain\n",
    "    \"\"\"\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        if method == 0:\n",
    "            return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "        elif method == 1:\n",
    "            return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "        else:\n",
    "            raise ValueError('method must be 0 or 1.')\n",
    "    return 0.\n",
    "\n",
    "\n",
    "def ndcg_at_k(r, k, method=0):\n",
    "    \"\"\"Score is normalized discounted cumulative gain (ndcg)\n",
    "    Relevance is positive real values.  Can use binary\n",
    "    as the previous methods.\n",
    "    Example from\n",
    "    http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
    "    >>> r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "    >>> ndcg_at_k(r, 1)\n",
    "    1.0\n",
    "    >>> r = [2, 1, 2, 0]\n",
    "    >>> ndcg_at_k(r, 4)\n",
    "    0.9203032077642922\n",
    "    >>> ndcg_at_k(r, 4, method=1)\n",
    "    0.96519546960144276\n",
    "    >>> ndcg_at_k([0], 1)\n",
    "    0.0\n",
    "    >>> ndcg_at_k([1], 2)\n",
    "    1.0\n",
    "    Args:\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "        k: Number of results to consider\n",
    "        method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "                If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "    Returns:\n",
    "        Normalized discounted cumulative gain\n",
    "    \"\"\"\n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k, method) / dcg_max\n",
    "\n",
    "score = []\n",
    "for n in range(splits):\n",
    "    result = pd.read_csv('predict%d.csv'%n)\n",
    "    result['rel'] = result.apply(relevance,axis=1)\n",
    "    score_n = 0\n",
    "    for srch_id in result[\"SearchId\"].unique():\n",
    "        #use NDCG@38 as per Kaggle site\n",
    "        score_n += ndcg_at_k(result.loc[result[\"SearchId\"]==srch_id,\"rel\"].values,38)\n",
    "    score.append(score_n / len(result[\"SearchId\"].unique()))\n",
    "print(score)\n",
    "print(\"AVERAGED SCORE: %s\"%np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,i in enumerate(score):\n",
    "    print(\"SPLIT %d: %.16f\"%(n,i))\n",
    "print(\"AVERAGED SCORE: %.16f +/- %.16f\"%(np.mean(score),1.96*np.std(score)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### show correlations with the target booking_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()[\"booking_bool\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### comp#_inv has some weird values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what are -1 values? Expedia has no availability, but competitor does? Why would Expedia then show the hotel?\n",
    "#(Create new feature based on availablility?)\n",
    "print(df[\"comp1_inv\"].value_counts())\n",
    "print(\"Number of NaNs: %d\"%df[\"comp1_inv\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Not all searches lead to a booking, but all do have a clicked item!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_book = set(df.loc[df[\"booking_bool\"]==1,\"srch_id\"].unique())\n",
    "ids = set(df[\"srch_id\"].unique())\n",
    "print(\"Number of unique searches: %d\"%len(ids))\n",
    "print(\"Number of unique searches resulting in booking: %d\"%len(id_book))\n",
    "print(\"Number of unique searches without booking: %d\"%len(ids-id_book))\n",
    "id_click = set(df.loc[df[\"click_bool\"]==1,\"srch_id\"].unique())\n",
    "print(\"Number of unique searches with clicks: %d\"%len(id_click))\n",
    "print(\"Number of unique searches without clicks: %d\"%len(ids-id_click))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get N largest values from column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[np.argsort(df[\"price_usd\"].values)[-1:-10:-1],[\"srch_id\",\"price_usd\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### show histogram of all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.hist(df.columns.values,figsize=(8,10*len(df.columns)),layout=(len(df.columns),1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
